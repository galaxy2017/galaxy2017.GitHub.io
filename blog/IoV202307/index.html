<!doctype html>
<html lang="zh-Hans" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">边缘计算相关论文笔记（2023年7月） | 胖螺</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://blog.luomoe.com/blog/IoV202307"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="keywords" content="胖螺,JavaScript,python,tensorflow,nvidia"><meta data-rh="true" property="og:title" content="边缘计算相关论文笔记（2023年7月） | 胖螺"><meta data-rh="true" name="description" content="001  Energy-Efficient Joint Task Offloading and Resource Allocation in OFDMA-Based Collaborative Edge Computing"><meta data-rh="true" property="og:description" content="001  Energy-Efficient Joint Task Offloading and Resource Allocation in OFDMA-Based Collaborative Edge Computing"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-07-31T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://luomoe.com"><meta data-rh="true" property="article:tag" content="Edge Computing,Offloading,Vehicles"><link data-rh="true" rel="icon" href="https://img.up.cdn.nahida.cn/2020/03/cropped-logo2-1.png"><link data-rh="true" rel="canonical" href="https://blog.luomoe.com/blog/IoV202307"><link data-rh="true" rel="alternate" href="https://blog.luomoe.com/blog/IoV202307" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://blog.luomoe.com/blog/IoV202307" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="胖螺 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="胖螺 Atom Feed"><link rel="stylesheet" href="/assets/css/styles.dfc5b64c.css">
<link rel="preload" href="/assets/js/runtime~main.b2abe4ed.js" as="script">
<link rel="preload" href="/assets/js/main.cf17977a.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="https://img.up.cdn.nahida.cn/2020/03/cropped-logo2-1.png" alt="胖螺" class="themedImage_ToTc themedImage--light_HNdA"><img src="https://img.up.cdn.nahida.cn/2020/03/cropped-logo2-1.png" alt="胖螺" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">胖螺</b></a></div><div class="navbar__items navbar__items--right"><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div><a class="navbar__item navbar__link" href="/docs/intro">笔记</a><a class="navbar__item navbar__link" href="/blog/welcome">博客</a><a class="navbar__item navbar__link" href="/blog/links">友链</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="最近博文导航"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/IoV202307">边缘计算相关论文笔记（2023年7月）</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Technology20230729">解决NVIDIA 30/40系列显卡与tensorflow 1.15 不兼容的问题</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/IoV202306">边缘计算相关论文笔记（2023年6月）</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/IoV202305">边缘计算相关论文笔记（2023年5月）</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/links">友情链接</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">边缘计算相关论文笔记（2023年7月）</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-07-31T00:00:00.000Z" itemprop="datePublished">2023年7月31日</time> · <!-- -->阅读需 7 分钟</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://luomoe.com" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://img.up.cdn.nahida.cn/2020/03/cropped-logo2-1.png" alt="Pangluo"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://luomoe.com" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Pangluo</span></a></div><small class="avatar__subtitle" itemprop="description">A salted fish</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="001--energy-efficient-joint-task-offloading-and-resource-allocation-in-ofdma-based-collaborative-edge-computing">001  Energy-Efficient Joint Task Offloading and Resource Allocation in OFDMA-Based Collaborative Edge Computing<a class="hash-link" href="#001--energy-efficient-joint-task-offloading-and-resource-allocation-in-ofdma-based-collaborative-edge-computing" title="标题的直接链接">​</a></h2><p>This article is a study on OFDMA-based collaborative mobile edge computing (C-MEC). The article first introduces the background and advantages of C-MEC, and then presents a joint optimization problem for task offloading, collaborative decision making, and resource allocation. The article models a mixed integer nonlinear programming (MINLP) problem with the objective of minimizing the total energy consumption of all mobile users while satisfying task delay constraints. Since this problem is NP-hard, the article proposes a two-layer framework of alternating methods to solve it. In the first layer, the article utilizes an ant colony system (ACS)-based heuristic algorithm to optimize task offloading decisions; in the second layer, the article utilizes a deep reinforcement learning algorithm based on deep Q-networks (DQN) to optimize resource allocation. The article verifies the excellent performance of the proposed algorithm in terms of energy efficiency and task completion rate through simulation experiments. The experimental results show that the proposed algorithm can effectively reduce the energy consumption of mobile users and ensure the task completion within the specified time. In addition, the convergence and robustness of the algorithm are analyzed in the paper.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="002--the-case-for-fpga-based-edge-computing">002  The Case for FPGA-Based Edge Computing<a class="hash-link" href="#002--the-case-for-fpga-based-edge-computing" title="标题的直接链接">​</a></h2><p>This article focuses on an FPGA-based edge computing model that takes advantage of the customizability of FPGAs and the low latency of edge computing to accelerate the response time and save energy of mobile interactive applications. The article selects three typical computer vision applications as case studies, namely, handwritten digit recognition, object recognition, and face detection. The article experimentally compares the performance of four schemes: FPGA edge offload, CPU edge offload, CPU cloud offload, and mobile local processing, and the results show that FPGA edge offload outperforms the other schemes in terms of response time, execution time, and energy consumption. The article also explores data parallel processing methods between mobile and edge nodes to further reduce the response time of batch requests. The article concludes with a discussion of the advantages, limitations, and future research directions of the FPGA edge computing model.</p><h1>第二周</h1><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="003--joint-task-offloading-and-cache-placement-for-energy-efficient-mobile-edge-computing-systems">003  Joint Task Offloading and Cache Placement for Energy-Efficient Mobile Edge Computing Systems<a class="hash-link" href="#003--joint-task-offloading-and-cache-placement-for-energy-efficient-mobile-edge-computing-systems" title="标题的直接链接">​</a></h2><p>This article is about joint task cache placement and offloading design for cache-enabled multi-user Mobile Edge Computing (MEC) systems. The goal of the article is to minimize the total system-weighted energy consumption in the task caching and task arrival/execution phases, taking into account the constraints of cache capacity, task causality, and task completion deadline. The article first solves the optimal offline solution of the problem using the branch-and-bound (BnB) method, and then proposes two low-complexity schemes based on task popularity and convex relaxation. The article demonstrates the advantages of the proposed schemes over existing benchmark schemes through numerical results.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="004-energy-efficient-computation-offloading-in-mobile-edge-computing-systems-with-uncertainties">004 Energy-Efficient Computation Offloading in Mobile Edge Computing Systems With Uncertainties<a class="hash-link" href="#004-energy-efficient-computation-offloading-in-mobile-edge-computing-systems-with-uncertainties" title="标题的直接链接">​</a></h2><p>This article is about the problem of energy-efficient computational offloading in mobile edge computing systems. The article proposes a new approach to this problem that relaxes the strong assumptions on radio channel and network queue sizes made in existing research and takes into account the uncertainty inherent in the network. The article uses extreme value theory to limit the probability of occurrence of uncertain events and develops a column generation-based ε-bounded approximation algorithm to solve the posed problem. The algorithm is effective in finding a feasible solution that is less than (1 + ε) times the optimal solution. The article also implements the proposed scheme on an Android smartphone and conducts extensive experiments using real-world applications. The experimental results confirm that the energy consumption of the client device can be reduced by taking into account the inherent uncertainty in the computational offloading process. The proposed computational offloading scheme also significantly outperforms other schemes in terms of energy savings.</p><h1>第三周</h1><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="005-joint-power-control-and-computation-offloading-for-mobile-edge-networks">005 Joint power control and computation offloading for mobile edge networks<a class="hash-link" href="#005-joint-power-control-and-computation-offloading-for-mobile-edge-networks" title="标题的直接链接">​</a></h2><p>This article investigates how to minimize the energy consumption of mobile devices by offloading computationally intensive tasks to MEC servers, taking into account co-channel interference and task latency requirements. The article presents an analytical model to decouple power control and computational resource allocation and shows that the joint optimization problem is invex and can be solved by a CCP-based algorithm. The article also proves that the joint power and CPU cycle allocation problem is a type I invex problem, which guarantees that each KKT stabilization point of the problem is a global minimum. The article also provides an offloading decision criterion for optimal energy efficiency computation based on the partial derivatives of the total energy consumption of the mobile device.The article models the communication channel as block fading and the computational task as a tuple of input data size, required CPU cycles, and maximum latency. The article defines the transmission power, rate, latency, and energy consumption of each offloaded mobile device, as well as the local execution power, latency, and energy consumption. The article also introduces offloading decision variables to indicate whether a mobile device chooses to offload its task or not.The article proves that the total transmission energy consumption function is a concave function monotonically increasing with respect to each power configuration component. The article also derives a set of linear equations to represent the relationship between transmission power and computational resources, where the coefficient matrix is an inverse positive M matrix that depends on the CPU cycle allocation.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="006-joint-offloading-and-resource-allocation-using-deep-reinforcement-learning-in-mobile-edge-computing">006 Joint Offloading and Resource Allocation Using Deep Reinforcement Learning in Mobile Edge Computing<a class="hash-link" href="#006-joint-offloading-and-resource-allocation-using-deep-reinforcement-learning-in-mobile-edge-computing" title="标题的直接链接">​</a></h2><p>This article investigates the problem of partial task offloading and resource allocation in Mobile Edge Computing (MEC). The article proposes a Deep Reinforcement Learning (DRL)-based Energy Efficiency Algorithm (EEDRL) that decomposes the original non-convex optimization problem into two sub-problems, i.e., offloading ratio selection and resource allocation.The EEDRL employs an actor-critic network architecture, where the actor network learns the optimal mapping from the time-varying wireless channel to offloading ratios, and the critic network utilizes an advanced convex optimization algorithm to solve the the resource allocation subproblem.EEDRL devises an annealed Gaussian noise addition method for exploring more satisfactory offloading ratios in actor networks and explores different exploration strategies and verifies the generalization of the method. Numerical experiments are conducted to compare the method with various existing offloading schemes, and the results show that EEDRL is able to save up to 57.6% of energy consumption relative to binary offloading and achieves significant computation time speedups relative to the SQP algorithm. It is also shown that jointly optimizing the energy consumption of SMDs and MEC servers by choosing appropriate weighting factors for the MEC servers can reduce up to half of the total energy consumption, relative to a greedy strategy that only considers the energy reduction of SMDs.</p><h1>第四周</h1><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="007--energy-efficient-resource-management-in-uav-assisted-mobile-edge-computing">007  Energy-Efficient Resource Management in UAV-Assisted Mobile Edge Computing<a class="hash-link" href="#007--energy-efficient-resource-management-in-uav-assisted-mobile-edge-computing" title="标题的直接链接">​</a></h2><p>This paper investigates the energy efficiency optimization problem in UAV-assisted mobile edge computing systems with the goal of minimizing the energy consumption of mobile devices and UAVs. The paper considers factors such as UAV trajectory optimization, communication and computational resource allocation, and task offloading, and presents a non-convex optimization problem. To solve this problem, this paper introduces an algorithm based on block-by-block upper bound minimization (BSUM), which successively minimizes a tight upper bound of the objective function and updates the variables step by step. In this paper, we demonstrate the effectiveness of the proposed algorithm through numerical simulation results, which can significantly reduce the total energy consumption of the network compared to other benchmark algorithms.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="008--energy-efficient-task-offloading-and-resource-allocation-via-deep-reinforcement-learning-for-augmented-reality-in-mobile-edge-networks">008  Energy-Efficient Task Offloading and Resource Allocation via Deep Reinforcement Learning for Augmented Reality in Mobile Edge Networks<a class="hash-link" href="#008--energy-efficient-task-offloading-and-resource-allocation-via-deep-reinforcement-learning-for-augmented-reality-in-mobile-edge-networks" title="标题的直接链接">​</a></h2><p>This paper investigates the use of deep reinforcement learning in mobile edge networks for energy efficient task offloading and resource allocation optimization for augmented reality applications. The study builds a more specific and detailed model of an augmented reality application by dividing an application into five subtasks and considering the dependencies and latency requirements between the subtasks. In order to solve the hybrid problem of multi-user competition and cooperation and simultaneously satisfy the energy minimization and quality of service guarantee for each user, a multi-intelligent deep deterministic policy gradient (MADDPG) algorithm is proposed. The effectiveness and superiority of the proposed algorithm in single-edge server and multi-edge server systems are verified through simulation experiments.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>标签：</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/edge-computing">Edge Computing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/offloading">Offloading</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/vehicles">Vehicles</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Technology20230729"><div class="pagination-nav__sublabel">较旧一篇</div><div class="pagination-nav__label">解决NVIDIA 30/40系列显卡与tensorflow 1.15 不兼容的问题</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#001--energy-efficient-joint-task-offloading-and-resource-allocation-in-ofdma-based-collaborative-edge-computing" class="table-of-contents__link toc-highlight">001  Energy-Efficient Joint Task Offloading and Resource Allocation in OFDMA-Based Collaborative Edge Computing</a></li><li><a href="#002--the-case-for-fpga-based-edge-computing" class="table-of-contents__link toc-highlight">002  The Case for FPGA-Based Edge Computing</a></li><li><a href="#003--joint-task-offloading-and-cache-placement-for-energy-efficient-mobile-edge-computing-systems" class="table-of-contents__link toc-highlight">003  Joint Task Offloading and Cache Placement for Energy-Efficient Mobile Edge Computing Systems</a></li><li><a href="#004-energy-efficient-computation-offloading-in-mobile-edge-computing-systems-with-uncertainties" class="table-of-contents__link toc-highlight">004 Energy-Efficient Computation Offloading in Mobile Edge Computing Systems With Uncertainties</a></li><li><a href="#005-joint-power-control-and-computation-offloading-for-mobile-edge-networks" class="table-of-contents__link toc-highlight">005 Joint power control and computation offloading for mobile edge networks</a></li><li><a href="#006-joint-offloading-and-resource-allocation-using-deep-reinforcement-learning-in-mobile-edge-computing" class="table-of-contents__link toc-highlight">006 Joint Offloading and Resource Allocation Using Deep Reinforcement Learning in Mobile Edge Computing</a></li><li><a href="#007--energy-efficient-resource-management-in-uav-assisted-mobile-edge-computing" class="table-of-contents__link toc-highlight">007  Energy-Efficient Resource Management in UAV-Assisted Mobile Edge Computing</a></li><li><a href="#008--energy-efficient-task-offloading-and-resource-allocation-via-deep-reinforcement-learning-for-augmented-reality-in-mobile-edge-networks" class="table-of-contents__link toc-highlight">008  Energy-Efficient Task Offloading and Resource Allocation via Deep Reinforcement Learning for Augmented Reality in Mobile Edge Networks</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 胖螺 2020-2023 . <br>
                    <a href="https://www.nahida.cn/" target="_blank" style="color:#fff">纳西妲 世界第一可爱</a> <br>
                  <span style="text-align: center">  本网站由<a href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" target="_blank"><img src="https://img.up.cdn.nahida.cn/icon/upyun_logo5.png" width="53px" style="vertical-align: middle; display: inline-block;"></a>提供CDN加速/云存储服务</span>

        </div></div></div></footer></div>
<script src="/assets/js/runtime~main.b2abe4ed.js"></script>
<script src="/assets/js/main.cf17977a.js"></script>
</body>
</html>